%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
% \addcontentsline{toc}{chapter}{\tocEntry{Abstract}}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
%%%%% What is the problem?
% Not more than 3-4 sentences telling the reader what the problem is, in as simple English as possible
Everyday uses of audio recordings involve mixture signals: music contains a mixture of instruments playing together; in a meeting or conference, there is a mixture of human voices.
Although human listeners find it easy to focus their attention on a particular sound source, automatically counting and separating sources remains a challenging task.
For instance, when two instruments play the same note (unison) or when many people speak concurrently (``cocktail party''), the overlap is severe, highlighting the need for new representations and powerful models in order to address these two tasks.
%%%%% Why is the problem hard? 
% What has eluded us in solving it?
% What does the literature say about this problem?
% What are the obstacles/challenges? Why is it non-trivial? 
% Audio signals that overlap in time and frequency are a common source of difficulty for many tasks that process or analyze these mixtures.
A common assumption when separating sources in the time-frequency domain (as is the case of non-negative matrix factorization) is that they are not fully overlapped.
Accurately estimating the number of sources is very important for real-world scenarios.
However, most approaches have relied on non-overlapping segments to facilitate ``counting by detection'' but with higher amount of overlap, strategies need to shift towards directly inferring a count.
%%%%% What is your approach/result to solving this problem?
% How come you solved it? 
% sit up and take notice claims that your thesis will plan to prove/demonstrate 
To address both problems, we used conventional signal processing techniques as well as deep neural networks (DNN).
We first address the source separation problem for unison instrument mixtures, 
thoroughly studying the distinct spectro-temporal modulations caused by vibrato. 
To exploit these modulations, we develop a method based on time warping informed by an estimate of the fundamental frequency. 
For cases where such estimates are not available, we present a model inspired by the way humans group time-varying sources (common fate).
This contribution comes with a novel representation that increases separability for overlapped and modulated sources on unison mixtures but also improve vocal/accompaniment separation when used as an input for a DNN model.
We approach the count estimation task by study how humans can solve this tasks by conducting a number listening experiments, confirming that humans are only able to correctly estimate up to four sources.
% for both, overlapped speech as well as polyphonic music recordings. 
To answer the question if machines can perform similarly, we present a DNN architecture, trained to estimate number of concurrent speakers in a cocktail party scenario of up to ten speakers.
Our results show improvements compared to other methods and the model even outperformed humans on the same task.
%%%%% What is the consequence of your approach?
% So, now that youâ€™ve made me sit up and take notice, what is the impact? 
% What does your approach/result enable?
In this thesis, we affirmed the importance of modulation based signal separation. 
Our speaker count estimation model enables applications such as crowd surveillance or speaker diarization in challenging environments.
Finally, we inspected our count estimation model to glean insights on how it achieves its high performance, finding that modulations also play a crucial role in its workings.

\vfill

\begin{otherlanguage}{ngerman}
\pdfbookmark[1]{Zusammenfassung}{Zusammenfassung}
\chapter*{Zusammenfassung}
t.b.a\dots
\end{otherlanguage}

\endgroup

\vfill
