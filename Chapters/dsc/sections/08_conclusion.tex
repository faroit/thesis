\section{Conclusion}%
\label{sec:conclusion}
We introduced the task of estimating the maximum number of concurrent speakers in a simulated ``cocktail-party'' environment using a data-driven approach, discussing how to frame this task in a deep learning context.
Building upon earlier work, we investigated what method is best to output integer source count estimates and also defined suitable cost functions for optimization.
In a comprehensive study we performed experiments to evaluate different network architectures.
Furthermore, we investigated and evaluated other important parameters such as input representations or the input duration.
Our final proposed model uses a convolutional recurrent (CRNN) architecture, based on classification at the network's output.
Compared to several baselines, our proposed model has a significantly lower error rate;
it achieves error rates of less then 0.3 speakers in mean absolute error for classifying zero to ten speakers---a decrease of 28.95\% compared to~\cite{stoeter17}.
In further simulations, we revealed that our model is robust to unseen languages (such as Chinese), as well as varying acoustical conditions (except for reverberation, where the error increased significantly).
However, including reverberate samples in the training reduces the error.
Additionally, we conducted a perceptual experiment showing that these results clearly outperform humans.
Lastly, in an ablation study, we found that the CRNN uses a strategy to segment phonemes/syllables to estimate the count.
Hence, we hypothesize that a speaker count estimate is influenced by the average speaking rates of certain languages.
Finally, to underpin this hypothesis, we showed that the speaking rate has a significant effect on the error of our model.
