% from common fate
\section{Modulation Spectrogram based Separation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Studies} % (fold)
% \label{sec:experiment}
\kant[1-4]


% Intro commonfate START
% Unknown modulation!
Sound source separation continues to be a very active field of research~\cite{vincent14} with a variety of applications. Many recent contributions are based on the popular non-negative matrix factorization (NMF). The way NMF factorizes a spectrogram matrix into frequency and activation templates makes it possible to easily design algorithms in an intuitive way. At the same time, it provides a rank reduction, needed to decompose mixtures into their source components.
In the past, many NMF-based source separation methods have been developed~\cite{smaragdis03, smaragdis04, virtanen07}. Expanding the NMF to tensors allows to incorporate more complex models, useful in many applications like multi-channel separation. Extensions to NMF such as shift-invariance or convolutions were carried over to non-negative tensor (NTF) based algorithms~\cite{fitzgerald05, fitzgerald08, fitzgerald06, fevotte10, ozerov11}. These approaches, relying on decomposing mixtures of musical instruments, work well when certain assumptions hold to be true.
One is that spectral harmonics only partially overlap. However, when two sources share the same fundamental frequency, almost all partials do overlap, making it difficult for NMF-based algorithms to learn unique templates. Another assumption is that all spectral and temporal templates semantically correspond to musical notes, forming a dictionary of musically meaningful atoms.
This does not hold for instruments with time-varying fluctuations. These effects can typically be found in musical instruments like strings and brass, when played with vibrato. In a setting where two musical instruments with vibrato play in unison, both assumptions could break, which makes it a challenging scenario~\cite{stoeter14}.
% Intro commonfate START

When processing such mixtures with a representation based on a standard NMF and the magnitude spectrogram, it is hard to model the sources with only a few spectral templates. Instead of increasing the number of templates per source, Hennequin proposes~\cite{hennequin11} frequency-dependent activation matrices by using a source/filter-based model.
Since the vibrato does not only cause frequency modulation (FM) but also amplitude modulation (AM), so-called modulation spectra can be used to identify the modulation pattern. This is often calculated by taking the Fourier transform of a magnitude spectrum. Thus, the \emph{modulation spectrogram} has already gathered much attention in speech recognition~\cite{greenberg97,kingsbury98} and classification~\cite{kinnunen08, markaki09}.
Barker and Virtanen~\cite{barker13} were the first to propose a modulation tensor representation for single channel source separation. This allows to elegantly apply factorization on the tensor by using the well known PARAFAC/CANDECOMP (CP) decomposition.

In this work we introduce a novel tensor signal representation which additionally exploits similarities in the frequency direction. We can therefore make use of dependencies between modulations of neighbouring bins. This is similar to the recently proposed High-Resolution Nonnegative Matrix Factorization
model that accounts for dependencies in the time-frequency plane (HR-NMF
~\cite{badeau11}). In short, HR-NMF models each complex entry of a time-frequency transform of an audio signal as a linear combination of its neighbours, enabling the modelling of damped sinusoids, along with an independent
innovation. This model was generalized to multichannel mixtures in~\cite{badeau13a,badeau14}
and was shown to provide considerably better oracle performance for source separation than alternative models in~\cite{magron15a}.
Indeed, even though some variational approximations were introduced
in~\cite{badeau13} to strongly reduce their complexity,
those algorithms are often demanding for practical applications.
In this paper, we propose to relax some assumptions of HR-NMF in the interest of simplifying the estimation procedure. The core idea is to divide the complex spectrogram into modulation patches in order to group common modulation in time and frequency direction. We call this the \emph{Common Fate Model} (CFM), borrowing from the Gestalt theory, which describes how human perception merges objects that move together over time. Bregman~\cite{bregman94} described the Common Fate theory for auditory scene analysis as the ability to group sound objects based on their common motion over time, as occurs with frequency modulations of harmonic partials. As outlined by Bregman, the human ability to detect and group sound sources by small differences in FM and AM is outstanding. Also, it turns out that humans are especially sensitive to modulation frequencies around 5~Hz, which is the typical vibrato frequency that many musicians produce naturally.
% Intro commonfate END

%\from dafx
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Separating by Amplitude Modulation}
\label{sub:am}

\begin{figure}[H]
    \centering
    \tiny
    \subfloat[Input]{
       \includegraphics[width=0.92\columnwidth]{Chapters/dafx/figures/Timepdf-crop.png}	   		  \hspace{-7mm}
    }\hfill
    \subfloat[Spectrogram]{
       \input{Chapters/dafx/figures/AMPlots/STFT.tex}%
    }%
    \subfloat[Tensor Slice]{
       \input{Chapters/dafx/figures/AMPlots/Tmod.tex}%
    }\hfill

    \subfloat[NMF]{
     	\input{Chapters/dafx/figures/AMPlots/WH.tex}%
    }\hfill
    \subfloat[Non-Negative Tensor Factorization]{
       \input{Chapters/dafx/figures/AMPlots/GAS.tex}%
    }\hfill
    \caption{Example of separating a mixture of two amplitude modulated signals by NMF and Modulation-NTF. \\ \textbf{(a)} Mixture of two sinusoids at $440$ Hz with AM of $4.7$ Hz and $12.6$ Hz (fs=$8$ kHz), \textbf{(b)} STFT (FFT length = 256), \textbf{(c)} Slice of Modulation Tensor (FFT length = 256),  \textbf{(d)} $\mathbf{W} \times \mathbf{H}$ Result of Non-Negative Matrix Factorization ($\beta = 1$) after 100 iterations, \textbf{(e)}  $\mathbf{G} \times \mathbf{A} \times \mathbf{S} $ Result of Non-Negative Tensor Factorization ($\beta = 1$) after 100 iterations,}
    \label{fig:tensor}
\end{figure}

Amplitude modulation is normally not present, isolated in acoustical instruments. However electric pianos like Rhodes or Wurlitzers can generate a tremolo effect. Using the amplitude modulation to separate mixtures has already been done in \cite{li09} which makes use of the concept of \emph{Common Amplitude Modulation}.

\textsc{CAM} is effectively the property of harmonics that share the same amplitude modulation across the bins.
One way of analyzing it is a modulation spectrogram which is a frequency-frequency representation of a time domain input signal.
There are also other ways to generate a modulation spectrum.
A complete signal representation can be archived by a modulation tensor which holds the modulation spectrograms for each time frame.

% TODO add more info about how to form a modulation tensor for AM.
% the key point is that after the TF transform the magnitude has to be taken to compute the amplitude modulation. Computing the frequency modulation spectrogram is not possble in a simple way. WHY?

% Known modulation
Barker and Virtanen \cite{barker13} found a way to utilize the modulation tensor for single channel source separation. Standard NMF models the spectrogram by the sum of $K$ components which are each factored into frequency/basis and time/activations components:
\begin{equation}
   \mathbf{X}_{n,m} \approx \sum_{k=1}^{K}\mathbf{W_{n,k}}\times \mathbf{H_{k,m}}.
\end{equation}
Non-negative Tensor factorization approximates a modulation tensor by a product of three matrices containing the frequency/basis, time/activation signals, and the modulation gain for each component. Compared to \cite{barker13} we choose to generate the modulation tensor in way that is simpler and easier to invert. Barker and Virtanen use a Gammatone filter bank and  rectification to model the characteristics of the human auditory system. We used a two-stage DFT filter bank where the modulation domain is based on  magnitude spectrograms. Although this can give perceptually less optimal results, each step can be directly inverted by using the complex representation. Barker already showed that the NTF based approach gives better results on speech signals. We found that this approach can be used to separate two instrument mixtures by their amplitude modulation characteristics and is therefore ideal for the unison scenario.

In Figure~\ref{fig:sk_tensor} we show the factorization of a simple amplitude modulated input signal for comparison. The signal consists of two sinusoids which are linearly mixed. Both share the same carrier frequency but have different amplitude modulation frequencies. We choose a factorization into $K=2$ components. From the activation components one can see that NMF is not able to separate the two signals sufficiently. NTF gives a smoother activation matrix and is able to generate the output with the separated amplitude modulations on each sinusoid. The modulation frequency gain matrix shows the two modulation frequency templates and the DC-component.

\begin{figure}[H]
\begin{center}
\begin{tabular}{c}
	\\
   Spectrogram of two sinusoids with same carrier\\
   frequency but different amplitude modulation frequency.\\[6pt]
	 \\
    Spectrogram of two sinusoids with same carrier\\
    frequency but different amplitude modulation frequency.\\[6pt]
	\input{Chapters/dafx/figures/AMPlots/WH.tex} \\
    Non-Negative Matrix Factorization \\[6pt]
	 \\
    Non-Negative Tensor Factorization\\[6pt]
\end{tabular}
\caption{Example of processing a non-stationary amplitude modulated signal with NMF and Modulation-NTF}
\label{fig:sk_tensor}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[block/.style={draw, minimum width=40pt, outer sep=0pt}]
  % small STFTs
  \node(A)[block, minimum height=30pt]             {STFT};
  \node(B)[block, below=of A, minimum height=30pt] {STFT};

   % huge STFT
  \node(STFT)[block, fit=(A)(B),left=of A.north west,anchor=north east, inner sep=0] {STFT};

  % arrow for input signal x
  \draw[-latex] ($(STFT.west) - (1, 0)$) |- (STFT.west) node [pos=0.75, above] (TextNode) {$x(n)$};

  % arrows to connect huge STFT with small STFTs plus labeling
  \draw[-latex] (STFT.east) |- (A.west) node [pos=0.75, above, font=\small] (TextNode) {$|x_c(n)|$};
  \draw[-latex] (STFT.east) |- (B.west) node [pos=0.75, above, font=\small] (TextNode) {$|x_c(n)|$};

  % arrows from node A to right side
  \draw[-latex] ($(A.east) + (0,0.3)$) -- ($(A.east) + (1,0.3)$);
  \draw[-latex] ($(A.east)$) -- ($(A.east) + (1,0)$);
  \draw[-latex] ($(A.east) + (0,-0.3)$) -- ($(A.east) + (1,-0.3)$);

  % arrows from node B to right side
  \draw[-latex] ($(B.east) + (0,0.3)$) -- ($(B.east) + (1,0.3)$);
  \draw[-latex] ($(B.east)$) -- ($(B.east) + (1,0)$);
  \draw[-latex] ($(B.east) + (0,-0.3)$) -- ($(B.east) + (1,-0.3)$);


  % dotted lines between small STFTs
  \draw[dotted] ($(A.south) + (0, -0.3)$) |- ($(B.north) + (0, 0.3)$);
\end{tikzpicture}
\caption{Demonstration of signal separation based on NTF}
\label{fig:sk_ntfdemo}
\end{center}
\end{figure}
