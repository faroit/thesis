%!TEX root = ../stoeter_sourcecount.tex
\section{Introduction}%
\label{sec:introduction}
% Introduce the task of estimating the maximum number of concurrent speakers in a single-channel mixture.
% * Lets start right into the task
% Source Separation (count estimate make blind SS fully blind)
In a ``cocktail-party'' scenario, one or more microphones capture the signal from many concurrent speakers. In this setting, different applications may be envisioned such as localization, crowd monitoring, surveillance, speech recognition, speaker separation, etc.
When devising a system for such a task, it is typically assumed that the actual number of concurrent speakers is known.
This assumption turns out to be of paramount importance for the effectiveness of subsequent processing.
Notably, for separation algorithms~\cite{common10},
real world systems do not straightforwardly provide information about the actual number of concurrent speakers.
% Assuming knowledge of speaker counts thus appears more as convenient than as realistic in practice.
It therefore is desirable to close the gap between theory and practice by devising reliable methods to estimate the number of sound sources in realistic environments.
Surprisingly, very few methods exist for this purpose in an audio context, in particular from a single microphone recording.

\par

% TODO: Maybe mention model selection, spectral clustering, gap statistics etc.
%% Transition paragraphs
% Describe two ways of getting the number of speakers: Counting vs Estimation
From a theoretical perspective, estimating the number of concurrent speakers is closely related to the more difficult problem of \textit{identifying} them, which is the topic of speaker diarization~\cite{angueramiro12, rouvier13, rouvier15, ramaiah17}. Intuitively, if a system is able to tell who speaks when, it is naturally also able to tell how many speakers are actually active in a mixture. We call this ``counting by detection''.
As diarization only works when a clear segmentation is possible, the first step of such a strategy often is to find homogeneous segments in the audio where only one speaker is active.
The segment borders can be found by speaker change detection~\cite{Yin17}.
These homogeneous segments are used to discriminate and temporally locate the speakers within a given recording.
When sources are simultaneously active, as in real cocktail party environments, such a segmentation is hardly possible.
In fact, overlapping speech segments typically are a major source of error in speaker diarization~\cite{angueramiro12}.
To improve the robustness of these detection-based methods, a number of approaches attempt to detect and possibly reject the overlapping speech segments to improve performance~\cite{boakye08, huijbregts09, geiger13, andrei17}.
In any case, diarization appears as a very complex problem to tackle when one is only interested in the number of concurrent speakers.
% * Briefly explain differences between counting by detection and directly estimate a count
% with respect to regression or classification. We want to directly estimate the count!
% * Explain how humans count/estimate.
% * Indications that humans are able to do directly estimate vision.
% * How do humans do count and why can't machines?
\par
When speaker overlap is as prevalent as in a ``cocktail-party'' scenario, developing an algorithm to detect the number of speakers is challenging.
This is in contrast to humans where we know that humans are excellent in segregating one source from a mixture~\cite{bregman} and tend to use this skill to perceptually segregate speakers before they can estimate a count, as highlighted, e.g.\ in~\cite{kawashima15}.
As shown in~\cite{kashino96, kawashima15}, humans are able to correctly estimate up to three simultaneously active speakers without using spatial information.
Similarly, in music, psycho-acoustic researchers came up with a ``one-two-three-many'' hypothesis~\cite{huron89, stoeter13, schoeffler13}.
The question if machines could outperform humans, or if they are subject to similar limitations, remains to be answered.
%
\par
Identifying isolated sources in realistic mixtures is challenging~\cite{bregman} and psychology studies in vision~\cite{jevons1871} have shown that humans can instantly estimate the number of objects without actually counting and therefore identifying them.
This phenomenon is known as \textit{subitizing} and has been inspiring research in vision~\cite{chattopadhyay17}.
Since there are indications that the auditory system is also capable of subitizing sources~\cite{hoopen79}, we transfer this fact to the audio domain and directly attempt in this study to estimate the number of audio sources instead of counting them after identification.
We refer to this strategy as ``direct count estimation''.

\par

%% State-of-the-art
% Reference counting methods with restrictions to audio and concurrent speech.
% * Single-channel vs. multi-channel (harder problem is single-channel)
Directly estimating the number of sources in audio mixtures has many applications and appears as a reasonable objective that mimics the process of human perception.
Since humans do have two ears that provide spatial diversity, a first natural idea to imitate human performance is to exploit \textit{binaural} information to proceed to source count estimation.
In terms of signal processing, this is achieved by estimating directions of arrival (DoA) and clustering them~\cite{loesch08, araki09, arberet10, pavlidi12, drude14_icassp, mirzaei15, walter15, Pasha17_reverb}.
However, many audio devices provide only a single microphone signal, and being able to also count sources in that case is desirable. Thus, the single-channel scenario has been considered in many studies:
\par
One of the first methods was proposed 2003 by Arai~\cite{arai03}.
It is based on the assumption that speech mixed from more than one speaker has a more complex amplitude modulation pattern than a single speaker.
The modulation pattern is aggregated and used as a decision function to distinguish between different number of speakers.
In~\cite{sayoud10}, the authors propose an energy feature based on temporally averaged mel filter outputs.
The number of concurrent speakers was determined by manually determining thresholds that best match individual speaker counts.
In a more recent work,
Xu et.al.~\cite{xu13} estimate the number of speakers by applying hierarchical clustering on fixed-length audio segments using mel frequency cepstral coefficients (MFCCs) and additional pitch features.
The method assumes non-overlapped speech and was evaluated on real world data of 20 hours duration and an average count estimation error of one speaker is reported using excerpts of eight-minutes duration and featuring up to eight speakers.
In another vein, Andrei et.al.~\cite{andrei15_interspeech} proposed an algorithm which correlates single frames of multi-speaker mixtures with a set of single-speaker utterances.
The resulting score was then used to estimate the number of speakers using thresholds.

\par

%% What is the gap?
In all the aforementioned methods, the speaker count estimation problem was devised.
The different strategies undertaken there rely on classical and grounded signal processing strategies and exhibit fair performance in a controlled setup.
However, our experience shows (see Section~\ref{sec:evaluation}) that they leave much room for improvement when applied to more diverse and challenging signals than those corresponding to their targeted applications, notably in the case of many different and constantly overlapping speakers.
% * Existing single-channel methods require segments where only a single speaker is active.
This is due to their main common weakness, which is to rely on the assumption that there are segments where only one speaker is active, in a way that is similar to the classical speaker diarization studies mentioned before.
In~\cite{stoeter17} a first data-driven approach based on a recurrent network was presented, motivated by the recent and impressive successes of deep learning approaches in various audio tasks like speech separation~\cite{yu16, hershey16, grais17} and speaker diarization~\cite{yella14, hruz16, garciaromero17}.
The methods proposed in~\cite{stoeter17} to address speaker count estimation using deep learning were built upon recent methods to count objects in images, which is a popular application with many contributions from the deep learning community~\cite{wang15, chattopadhyay17, khan16, segui15, zhang15, arteta16, marsden16, boominathan16, zhang2015salient}.
In~\cite{stoeter17} two main paradigms were evaluated: a) count estimation as regression problem, where the systems are directly trained to output the number of objects as a point estimate, and b) classification, where every possible number of objects is encoded as a different class and the output of a predicting system corresponds to a probability distribution over these classes.
The results of the proposed method indicated that a classification based neural network performed better than one based on regression.
One drawback however is that the maximum number of speakers (the number of classes) is known in advance.

% Many tasks in machine learning are formulated as classification problems and many models were proposed to address count estimation in this setup~\cite{segui15, zhang2015salient, khan16}, with good performance.

\par

In this study, we build upon~\cite{stoeter17} and focus on the network architecture design, as well as on finding limitations for different test scenarios.
This work makes the following contributions:
%% List of Contributions
% * Defining the problem of Estimating Number of Concurrent Sources.
i) we generalize the problem formulation by fusing classification and regression, which allows to estimate discrete outputs while controlling the error term. This is done by picking a point estimate from a full posterior distribution provided by the deep architectures;
% * Influence of three different problem formulations: regression, poisson regression. classification
% * Solution: Investigation of several deep learning architectures.
ii) in addition to the recurrent network introduced in~\cite{stoeter17}, we propose alternative speaker-independent neural network architectures based on the convolution operation to improve count estimation.
Each of the proposed networks is adjusted to estimate the number of speakers from audio segments shorter than 10 seconds;
iii) we test the performance of these networks in multiple experiments and compare them to several baseline methods, pointing out possible limitations.
Furthermore, we present a statistical analysis of the results to determine whether classification outperforms regression for all architectures;
% * Experiments aim to identify the learned strategy.
iv) we conducted a listening experiment to relate the best-performing machine to human performance.
We describe one of the strategies taken by the data-driven approach that might explain its superior performance.
Finally, for the sake of reproducibility, the trained networks (models) as well as the test dataset are made available on the accompanying website\footnote{\url{https://www.audiolabs-erlangen.de/resources/2017-CountNet}.}.
\par
%% Organisation
The remainder of this paper is organized as follows. In Section~\ref{sec:problem_formulation}, we describe the count estimation problem formally and the general ideas we propose to tackle it.
In Section~\ref{sec:supervised_learning}, we propose several architectures, each of them adjusted to estimate the number of speakers from short audio segments of less than 10~s.
In Section~\ref{sec:hyperparameters}, we then assess several common hyper parameters for all of our proposed architectures, so that we are able to propose a single, best performing model.
In Section~\ref{sec:evaluation} this model is compared to several baseline systems under various acoustical conditions.
Additionally, we compare the proposed method to human performance.
We point out possible limitations and provide indications for the strategy being taken by the DNN in Section~\ref{sec:ablation} before we conclude in Section~\ref{sec:conclusion}.
